<!DOCTYPE html>
<meta charset="UTF-8">
<html>
<!--
   This is a simple example of applying image textures to
   3D objects.  There are popup menus that allow the user
   to select an object, a texture image, and a base color
   for the object.  The color from the texture is multiplied
   by the base color to get the color for the surface.
   The surface also has some white specular reflection.
   
   Most of the comments on the code relate to texturing.
-->
<head>
<title>WebGPU Objects With Image Textures</title>
<style>
    body {
        background-color: #EEEEEE;
    }
    label {
        white-space: pre;
        margin-left: 25px;
    }
</style>

<script src="wgpu-matrix.min.js"></script>  <!-- matrix and vector algebra from Gregg Tavares -->
<script src="trackball-rotator.js"></script>
<script src="basic-object-models-IFS.js"></script>
<script src="teapot-model-IFS.js"></script>

<script>

"use strict";


const shaderSource = `
    struct VertexOutput {
        @builtin(position) coords : vec4f,
        @location(0) v_normal : vec3f,
        @location(1) v_eyeCoords : vec3f,
        @location(2) v_texcoords : vec2f  // texture coords are passed on to fragment shader
    }

    @group(0) @binding(0) var<uniform> modelview : mat4x4f;
    @group(0) @binding(1) var<uniform> projection : mat4x4f;
        
    @vertex
    fn vertMain( @location(0) a_coords : vec3f,
                 @location(1) a_normal : vec3f,
                 @location(2) a_texcoords :vec2f  // texture coordinates are a vertex attribute
             ) -> VertexOutput{
        var coords = vec4f(a_coords,1.0);
        var eyeCoords = modelview * coords;
        var output : VertexOutput;
        output.coords = projection * eyeCoords;
        output.v_normal = normalize(a_normal);
        output.v_eyeCoords = eyeCoords.xyz/eyeCoords.w;
        output.v_texcoords = a_texcoords;
        return output;
    }
    
    @group(1) @binding(0) var<uniform> baseColor : vec3f;    
    @group(1) @binding(1) var<uniform> normalMatrix : mat3x3f;
    
    @group(1) @binding(2) var tex : texture_2d<f32>;  // contains the texture image
    @group(1) @binding(3) var samp : sampler;         // for sampling the texture
    
    @fragment
    fn fragMain(
             @builtin(front_facing) front_facing : bool,
             @location(0) v_normal : vec3f, 
             @location(1) v_eyeCoords : vec3f,
             @location(2) v_texcoords : vec2f   // interpolated texture coordinates
     ) -> @location(0) vec4f {
        let normal = normalize( normalMatrix*v_normal );
        let viewDirection = normalize( -v_eyeCoords); 
        let colorFromTexture = textureSample( tex, samp, v_texcoords );  // get color from texture
        let diffuseColor = colorFromTexture.rgb * baseColor; // multiply texture color RGB by base color
        var color = vec3f(0.1);
        color += lightingEquation( vec4f(0,0,1,0), 0.8f, diffuseColor, v_eyeCoords,
                                                    normal, viewDirection);
        color += lightingEquation( vec4f(7,12,-7,1), 0.25f, diffuseColor, v_eyeCoords,
                                                    normal, viewDirection);
        return vec4f(color, colorFromTexture.a);
    }
    
    /* simplified lighting equation, with white specular reflection */
    fn lightingEquation( lightPosition : vec4f, lightIntensity : f32, diffuseColor : vec3f, 
                                eyeCoords : vec3f, N : vec3f, V : vec3f )-> vec3f {
           // N is normal vector, V is direction to viewer.
        var L : vec3f;  // Light direction
        var R : vec3f;  // reflected light direction.
        if ( lightPosition.w == 0.0 ) {
            L = normalize( lightPosition.xyz );
        }
        else {
            L = normalize( lightPosition.xyz/lightPosition.w - eyeCoords );
        }
        if (dot(L,N) <= 0.0) { // light does not illuminate this side
            return vec3f(0.0);
        }
        var reflection = dot(L,N) * vec3f(lightIntensity) * diffuseColor.rgb;
        R = -reflect(L,N);
        if (dot(R,V) > 0.0) {
            let factor = pow(dot(R,V), 20);
            reflection += factor * vec3f(0.3*lightIntensity);
        }
        return reflection;
    }
`;

        
let context;
let device; 
let pipeline;
let depthTexture;

let bindBuffer0;
let bindBuffer1;
    
let bindGroup0; 

let currentObject; // Model data, including texture coordinates, for currently selected object.
let objects = [];  // Model data for all objects.  Model is selected using "Object" popup menu.

let bindGroup1;  // Bind group containing the current texture (and other fragment shader resources).
                 // This bind group changes when the user selects a new texture image.
let textureBindGroups = [];  // All textureBindGroups, indexed by the URL index in textureURL array.
let textureBindGroupDescriptor;  // For creating the texture bindGroup1's.

let waitingForFirstImage = true;  // To stop draw() from being called unilt first image is loaded.

let rotator;

const baseColors = [ // base material colors, selected by "Base Color" popup menu
        new Float32Array([ 1.0, 1.0, 1.0 ]),
        new Float32Array([ 1.0, 0.75, 0.75 ]),
        new Float32Array([ 0.75, 1.0, 0.75 ]),
        new Float32Array([ 0.75, 0.75, 1.0 ]),
        new Float32Array([ 1.0, 1.0, 0.66 ])
    ];

const textureURL = [  // URL for texture images, selected by "Texture Image" popup menu
        "textures/Earth-1024x512.jpg",
        "textures/NightEarth-512x256.jpg",
        "textures/mona-lisa.jpg",
        "textures/brick001.jpg",
        "textures/marble.jpg"
    ];

async function initWebGPU() {

   if (!navigator.gpu) {
      throw Error("WebGPU not supported in this browser.");
   }
   let adapter = await navigator.gpu.requestAdapter();
   if (!adapter) {
      throw Error("WebGPU is supported, but couldn't get WebGPU adapter.");
   }

   device = await adapter.requestDevice();

   let shader = device.createShaderModule({
      code: shaderSource
   });
   
   let canvas = document.getElementById("webgpuCanvas");
   context = canvas.getContext("webgpu");
   context.configure({
      device: device,
      format: navigator.gpu.getPreferredCanvasFormat(),
      alphaMode: "premultiplied"
   });

   let vertexBufferLayout = [
      { // first vertex buffer, for coords
         attributes: [ { shaderLocation:0, offset:0, format: "float32x3" } ],
         arrayStride: 12,
         stepMode: "vertex" 
      },
      { // second vertex buffer, for normals
         attributes: [ { shaderLocation:1, offset:0, format: "float32x3" } ],
         arrayStride: 12,
         stepMode: "vertex" 
      },
      { // third vertex buffer, for texture coordinates
         attributes: [ { shaderLocation:2, offset:0, format: "float32x2" } ],
         arrayStride: 8,
         stepMode: "vertex" 
      }
    ];

   let pipelineDescriptor = {
       vertex: {
          module: shader,
          entryPoint: "vertMain",
          buffers: vertexBufferLayout
       },
       fragment: {
          module: shader,
          entryPoint: "fragMain",
          targets: [{
            format: navigator.gpu.getPreferredCanvasFormat()
          }]
       },
       depthStencil: {  
          depthWriteEnabled: true,
          depthCompare: "less",
          format: "depth24plus",
       },       
       primitive: {
          topology: "triangle-list"
       },
       layout: "auto"
    };
    
    pipeline = device.createRenderPipeline(pipelineDescriptor);
    
    bindBuffer0 = device.createBuffer({ 
       size: 256 + 64, 
       usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    }); 

    bindGroup0 = device.createBindGroup({
       layout: pipeline.getBindGroupLayout(0),
       entries: [
         { // projection matrix
            binding: 0,
            resource: {buffer: bindBuffer0, offset: 0, size: 64}
         },
         { // modelview matrix
            binding: 1,
            resource: {buffer: bindBuffer0, offset: 256, size: 64}
         }
       ]
    });

    let projectionMatrix = wgpuMatrix.mat4.perspective( Math.PI/4, 1, 1, 50 );
    device.queue.writeBuffer(bindBuffer0, 256, projectionMatrix);
    
    depthTexture = device.createTexture({ 
       size: [canvas.width, canvas.height],
       format: 'depth24plus',
       usage: GPUTextureUsage.RENDER_ATTACHMENT,
    });
    
    bindBuffer1 = device.createBuffer({
          // Holds only base color and normal matrix;
          // texture and sampler resources are not passed in buffers.
       size: 256 + 48, 
       usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });
    
    let sampler = device.createSampler({
       addressModeU: "repeat",  // texture repeats horizontally
       addressModeV: "repeat",  // texture repeats vertically
       magFilter: "linear",     // do linear filtering for better appearance
       minFilter: "linear"
    });
    
    textureBindGroupDescriptor = {  // for creating the bindGroup1 for each texture
       layout: pipeline.getBindGroupLayout(1),
       entries: [
         {  //  base color
            binding: 0,
            resource: {buffer: bindBuffer1, offset: 0, size: 12}
         },
         {  // normal matrix
            binding: 1,
            resource: {buffer: bindBuffer1, offset: 256, size: 48}
         },
         {  // for the texture; the resource will be set later, when the texture is created
             binding: 2
         },
         {  // the sampler
            binding: 3,
            resource: sampler
         }
       ]
    };
    
} // end initWebGPU()


/**
 *  This function is called during initialization and when the user selects a new
 *  object from the "Object" popup menu.  If the model has not yet been created,
 *  it is created and cached in the objects array.  The data for the model
 *  includes texture coordinates for each vertex.  GPU buffers are created to
 *  hold the texture coordinates and other model data, and the data is written
 *  to the buffers.  The buffers will be attached to the render pipeline in
 *  the draw() method.
 */
function installModel() {
   let modelNum = Number(document.getElementById("objectSelect").value);
   if ( ! objects[modelNum] ) { // Create the model.
        let model;
        switch (modelNum) { // Calling functions from basic-object-models-IFS.js,
                            // except the teapot is defined in teapot-model-IFS.js.
            case 0:  model = cube(5); break;
            case 1:  model = uvTorus(3,1,64,32); break;
            case 2:  model = uvCylinder(1.5,5.5); break;
            case 3:  model = uvCone(2.5,5.5); break;
            case 4:  model = uvSphere(3, 64, 32); break;
            default: model = teapotModel; break;
        }
        model.count = model.indices.length;
        model.coordsBuffer = device.createBuffer({ 
           size: model.vertexPositions.byteLength, 
           usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST
        });
        model.normalBuffer = device.createBuffer({ 
           size: model.vertexNormals.byteLength, 
           usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST
        });
        model.texcoordsBuffer = device.createBuffer({ 
           size: model.vertexTextureCoords.byteLength, 
           usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST
        });
        model.indexBuffer = device.createBuffer({ 
           size: model.indices.byteLength, 
           usage: GPUBufferUsage.INDEX | GPUBufferUsage.COPY_DST
        });
        device.queue.writeBuffer(model.coordsBuffer,0,model.vertexPositions);
        device.queue.writeBuffer(model.normalBuffer,0,model.vertexNormals);
        device.queue.writeBuffer(model.texcoordsBuffer,0,model.vertexTextureCoords);
        device.queue.writeBuffer(model.indexBuffer,0,model.indices);
        objects[modelNum] = model; // Cache the model for future use.
   }
   currentObject = objects[modelNum];
   draw();
}


/**
 *  This function is called during initialization and when the user selects a
 *  new image from the "Texture Image" popup menu.  If the texture has not yet
 *  been loaded, it is loaded and a bindGroup1 is created for it; the
 *  bind group is cached in the textureBindGroups array for use in the draw() function.
 *  This function is async because the image has to be loaded asynchronously.
 */
async function installTexture() {
    let imageNum = Number(document.getElementById("imageSelect").value);
    let URL = textureURL[imageNum];
    if ( ! textureBindGroups[imageNum]) {
       document.getElementById("message2").innerHTML = "Loading image from " + URL;
       let texture;
       try {
          texture = await loadTexture(URL);
       }
       catch (e) {
           if (waitingForFirstImage)
               document.getElementById("message2").innerHTML = "CAN'T LOAD IMAGE, PROGRAM CAN'T CONTINUE.";
           else
               document.getElementById("message2").innerHTML = "IMAGE LOAD FAILED FROM URL " + URL;
           console.log("Error loading image from " + URL + ": " + e);
           return;
       }
       textureBindGroupDescriptor.entries[2].resource = texture.createView();
       textureBindGroups[imageNum] = device.createBindGroup(textureBindGroupDescriptor);
       if (waitingForFirstImage) {
             // (install rotator an enable popup menus after first image has been loaded)
           document.getElementById("objectSelect").disabled = false;
           document.getElementById("colorSelect").disabled = false;
           document.getElementById("imageSelect").disabled = false;
           rotator = new TrackballRotator(context.canvas, draw, 12, [4,5,10]);
           waitingForFirstImage = false; 
        }
        document.getElementById("message2").innerHTML = "&nbsp;";
    }
    bindGroup1 = textureBindGroups[imageNum];
    draw();
}
async function loadTexture(URL) {
       // Standard method using the fetch API to get a texture from a ULR.
    let response = await fetch(URL);
    let blob = await response.blob();  // Get image data as a "blob".
    let imageBitmap = await createImageBitmap(blob);
    let texture = device.createTexture({
        size: [imageBitmap.width, imageBitmap.height],
        format: 'rgba8unorm',
        usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST |
                    GPUTextureUsage.RENDER_ATTACHMENT
    });
    device.queue.copyExternalImageToTexture(
       { source: imageBitmap, flipY: true },
       { texture: texture },
       [imageBitmap.width, imageBitmap.height]
    );
    return texture;
}


function installBaseColor() {
   let colorNum = Number(document.getElementById("colorSelect").value);
   device.queue.writeBuffer(bindBuffer1,0,baseColors[colorNum]);
   draw();
}


function draw() {
   if (waitingForFirstImage) {
      return; // make sure not to try this before first image has loaded
   }
   let viewMatrix = new Float32Array(rotator.getViewMatrix());
   if (currentObject === teapotModel) { // (teapot model has to be scaled down)
      wgpuMatrix.mat4.scale( viewMatrix, [0.25,0.25,0.25], viewMatrix );
   }
   device.queue.writeBuffer(bindBuffer0, 0, viewMatrix);
   let normalMatrix = wgpuMatrix.mat3.fromMat4(viewMatrix);
   device.queue.writeBuffer(bindBuffer1, 256, normalMatrix);
   let commandEncoder = device.createCommandEncoder();
   let renderPassDescriptor = {
      colorAttachments: [{
          clearValue: { r: 0.4, g: 0.4, b: 0.4, a: 1 },
          loadOp: "clear",
          storeOp: "store",
          view: context.getCurrentTexture().createView()
      }],
      depthStencilAttachment: {
        view: depthTexture.createView(),
        depthClearValue: 1.0,
        depthLoadOp: 'clear',
        depthStoreOp: 'store',
      }
   };
   let passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);
   passEncoder.setPipeline(pipeline);
   passEncoder.setBindGroup(0,bindGroup0);
   passEncoder.setBindGroup(1,bindGroup1);  // incldues the sampler and texture resources
   passEncoder.setVertexBuffer(0,currentObject.coordsBuffer);
   passEncoder.setVertexBuffer(1,currentObject.normalBuffer);
   passEncoder.setVertexBuffer(2,currentObject.texcoordsBuffer);  // texture coords for curren object
   passEncoder.setIndexBuffer(currentObject.indexBuffer,"uint16");
   passEncoder.drawIndexed(currentObject.count);
   passEncoder.end();
   let commandBuffer = commandEncoder.finish();
   device.queue.submit([commandBuffer]);       
}


async function init() {
   document.getElementById("colorSelect").disabled = true;
   document.getElementById("imageSelect").disabled = true;
   document.getElementById("objectSelect").disabled = true;
   try {
      await initWebGPU();
   }
   catch (e) {
       document.getElementById("message").innerHTML =
          "<span style='color:#AA0000; font-size:110%'><b>Error: Could not initialize WebGPU: </b>" + 
                    e.message + "</span>";
       return;
   }
   document.getElementById("colorSelect").value = "0";
   document.getElementById("colorSelect").onchange = installBaseColor;
   document.getElementById("imageSelect").value = "0";
   document.getElementById("imageSelect").onchange = installTexture;
   document.getElementById("objectSelect").value = "0";
   document.getElementById("objectSelect").onchange = installModel;
   installModel();
   installBaseColor();
   installTexture();
}

window.onload = init;

</script>
</head>
<body>
    
<h2>Textured Objects Using WebGPU</h2>

<noscript><hr><h3>Error: This page requires Javascript and a web browser that supports WebGPU</h3><hr></noscript>

<div style="float:left; margin-right:30px">


<p id="message">Drag your mouse on the object to rotate it.</p>

<p>
<label><b>Object:</b> <select id="objectSelect">
    <option value="0">Cube</option>
    <option value="1">Torus</option>
    <option value="2">Cylinder</option>
    <option value="3">Cone</option>
    <option value="4">Sphere</option>
    <option value="5">Teapot</option>
</select></label></p>

<p>
<label><b>Texture Image</b> <select id="imageSelect">
    <option value="0">Earth</option>
    <option value="1">Earth at night</option>
    <option value="2">Mona Lisa</option>
    <option value="3">Brick</option>
    <option value="4">Marble</option>
</select></label>
</p>

<p>
<label><b>Base Color:</b> <select id="colorSelect">
    <option value="0">White</option>
    <option value="1">Pink</option>
    <option value="2">Light Green</option>
    <option value="3">Light Blue</option>
    <option value="4">Light Yellow</option>
</select></label></p>

</div>

<p id="message2" style="color:red; font-weight:bold">&nbsp;</p>

<div id="canvas-holder">
   <canvas width=600 height=600 id="webgpuCanvas"></canvas>
</div>



</body>
</html>
