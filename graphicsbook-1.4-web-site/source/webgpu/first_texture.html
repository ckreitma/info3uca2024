<!DOCTYPE html>
<!--
   This program uses WebGPU to draw a square with a texture.
   The user can select from three possible textures: a trivial
   procedural texture, an image texture created from a data array,
   and an image texture created from a downloaded image.  If the
   image can't be loaded, then the third choice is disabled.
   
   All comments on the code are related to working with textures.
-->
<head>
<title>Basic WebGPU Example: Textured Square</title>
<style>
   body { 
      background-color: white;
   }
   #canvasholder {
      border: 2px solid black;
      display: inline-block;
   }
   canvas {
      display: block;
   }
</style>
<script>

"use strict";

const shaderSource = `

   struct VertexOutput {
      @builtin(position) position: vec4f,
      @location(0) texcoords : vec2f  
   }
   
   // Texture sampling requires texture coordinates, which are
   // usually given as a vertex attribute that is simply passed
   // on (after interpolation) to the fragment shader.  In this
   // program, the textures are 2D, so the texture coords are a
   // 2-vector.
   
   @vertex
   fn vertexMain(
            @location(0) coords : vec2f, 
            @location(1) texcoords : vec2f  // Texture coordinates.
         ) -> VertexOutput {  
      var output: VertexOutput;  
      output.position = vec4f( coords, 0, 1 );
      output.texcoords = texcoords; 
      return output;
   }
   
   // Texture sampling requires two variables in the fragment
   // shader.  One has type sampler, which specifies some details
   // of how the texture is sampled.  The other is the texture
   // itself.  The type texture_2d<f32> is for a 2D texture with
   // samples in which the color components are of type f32.
   // The values for these variables are resources in bind groups.
   // Note that sampler and texture variables are always declared
   // without an address space.
   
   @group(0) @binding(0) var samp : sampler;
   @group(0) @binding(1) var tex : texture_2d<f32>;
   
   // The textureSelect uniform variable just selects among the
   // three possible textures.  It gets a value of 1, 2, or 3 from
   // the JavaScript side.
   
   @group(0) @binding(2) var<uniform> textureSelect: u32;
   
   @fragment
   fn fragmentMain(@location(0) texcoords : vec2f) -> @location(0) vec4f{
      if (textureSelect == 1) {
            // Use the texture coordinates directly as the red and green
            // color components for the fragment.  This is a trivial
            // procedural texture, with no texture or sampler involved.
         return vec4f( texcoords, 0, 1);
      }
      else if (textureSelect == 2) {
            // The texture is a tiny 2-by-2 checkerboard texture (this is
            // specified in the bind group that is used in this case).
            // The texcoords are between 0 and 1.  Multiply them by
            // 5 to get five copies (each way) of the texture on the square.
            // It's important that the sampler use default ("nearest") filtering
            // for this texture.
         return textureSample( tex, samp, texcoords*5 );
      }
      else {
            // For this case, the bind group sets tex to be an image of
            // Mona Lisa, and samp is a sample that does "linear" filtering.
         return textureSample( tex, samp, texcoords );
      }
   }
`;

/* vertexData is an array containing the interleaved vertex data.
 * There are four floats for each of the four vertices -- two numbers
 * for the vertex coordinates and two for the texture coordinates.
 * Four vertices are used for drawing a square as a triangle strip.
 */
const vertexData = new Float32Array([
   /* coords */     /* texcoords */
    -0.8, -0.8,       0, 1,      // data for bottom left corner
     0.8, -0.8,       1, 1,      // data for bottom right corner
    -0.8,  0.8,       0, 0,      // data for top left corner
     0.8,  0.8,       1, 0,      // data for top right corner
]);



let context; 
let device;

let shader; 
let pipeline; 

let vertexBuffer;   // vertex coordinates and texture coordinates for the square
let uniformBuffer;  // contains the value for textureSelect in shader (1, 2, or 3)

let bindGroupLayout;

let bindGroup;  // The bind group that will be attached to the pipeline for drawing.
                // It will be equal to one of the following two bind groups.
let checkerboardBindGroup;  // Bind group containing the checkerboard texture.
                            // This is created as part of initialization.
let imageBindGroup;  // Bind group fo the Mona Lisa image texture.  This is created
                     // in loadTextureImage() after the image has been loaded.

async function initWebGPU() {

   if (!navigator.gpu) {
      throw Error("WebGPU not supported in this browser.");
   }
   let adapter = await navigator.gpu.requestAdapter();
   if (!adapter) {
      throw Error("WebGPU is supported, but couldn't get WebGPU adapter.");
   }

   device = await adapter.requestDevice();
   
   let canvas = document.getElementById("webgpuCanvas");
   context = canvas.getContext("webgpu");
   context.configure({
      device: device,
      format: navigator.gpu.getPreferredCanvasFormat(),
      alphaMode: "premultiplied"
   });

   device.pushErrorScope("validation");
   shader = device.createShaderModule({
      code: shaderSource
   });
   let error = await device.popErrorScope();
   if (error) {
      throw Error("Compilation error in shader; see Console for details.");
   }   
}


function createPipelineConfig() {

   let vertexBufferLayout = [
      { 
         attributes: [
                 // Vertex buffer contains vertex coords and texcoords, interleaved.
             { shaderLocation:0, offset:0, format: "float32x2" },
             { shaderLocation:1, offset:8, format: "float32x2" }
           ],
         arrayStride: 16, 
         stepMode: "vertex" 
      }
   ];
   
   bindGroupLayout = device.createBindGroupLayout({
      entries: [
         {    // for the sampler variable in the fragment shader
            binding: 0,
            visibility: GPUShaderStage.FRAGMENT,
            sampler: {
               type: "filtering" // Note: this is the default; the braces could be empty.
            }
         },
         {    // for the texture_2d<f32> variable in the fragment shader
            binding: 1,
            visibility: GPUShaderStage.FRAGMENT,
            texture: {
               sampleType: "float", // Note: All values are default; the braces could be empty.
               viewDimension: "2d",
               multisampled: false
            }
         },
         {    // for the uniform variable in the fragment shader
            binding: 2,
            visibility: GPUShaderStage.FRAGMENT,
            buffer: {
               type: "uniform"
            }
         }
      ]
   });
   
   let pipelineDescriptor = {
       vertex: {
          module: shader,
          entryPoint: "vertexMain",
          buffers: vertexBufferLayout
       },
       fragment: {
          module: shader,
          entryPoint: "fragmentMain",
          targets: [{
            format: navigator.gpu.getPreferredCanvasFormat()
          }]
       },
       primitive: {
          topology: "triangle-strip"
       },
       layout: device.createPipelineLayout({
          bindGroupLayouts: [bindGroupLayout]
       })
    };
    
   pipeline = device.createRenderPipeline(pipelineDescriptor);  
      
   vertexBuffer = device.createBuffer({
       size: vertexData.byteLength, 
       usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST
   });
   
   device.queue.writeBuffer(vertexBuffer, 0, vertexData);

   /* A sampler specifies how sampling is to be done, with properties
    * that control how the texture is repeated when texture coords
    * outside the range 0 to 1 are used.  The minification and magnification
    * filters and other properties can also be specified.
    */
   let checkerboardSampler = device.createSampler({
      addressModeU: "repeat",  // default is "clamp-to-edge"
      addressModeV: "repeat"
   });
   
   /* A texture uses memory on the GPU and is created by the device.
    * The parameter specifies properties of the texture.  The usage
    * property GPUTextureUsage.COPY_DST makes it possible to write
    * data to the texture using device.queue.writeTexture().
    */
   let checkerboardTexture = device.createTexture({
      size: [2,2],  // two pixels wide by two pixels high
      format: "rgba8unorm",  // one 8-bit unsigned integer for each color component
      usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST 
   });
   
   let textureData = new Uint8Array([
           // Color data for a 2-by-2 texture.  For format "rgba8unorm", an integer
           // in the range 0 to 255 is required for each of the four color
           // components for each pixel.
        255,200,200,255,   // pink for top left corner (0,0)
        180,180,255,255,   // blue for the top right corner (1,0)
        180,180,255,255,   // blue for the bottom left corner (0,1)
        255,255,200,255    // yellow for the bottom right corner (1,1)
   ]);
    
   /* Copy data to the texture memory.  This function is used when the data
    * is in a typed array or related JavaScript data structure; a different
    * method is used for copying an image to the texture.  The first parameter
    * specifies the texture and can also specify things like the mipmap level
    * that should be written. The second parameter is the data.  The third
    * parameter specifies aspects of the texture format.  The last parameter
    * specifies the size of the texture to be written.
    */
   device.queue.writeTexture(
            { texture: checkerboardTexture }, // texture to which data will be written
            textureData,         // data to be written
            { bytesPerRow: 8 },  // how many bytes in each row of pixels
            [2,2]  // size of the texture (width and height)
   );
   
   uniformBuffer = device.createBuffer({
      size: 4, 
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
   });
   
   device.queue.writeBuffer( uniformBuffer, 0, new Uint32Array([2]) );
   
   /* Create the bind group that will be attached to the pipeline when
    * the checkerboard texture is being used.
    */
   checkerboardBindGroup = device.createBindGroup({
      layout: bindGroupLayout,
      entries: [
         {    // The sampler. Note that the resource is the sampler itself.
            binding: 0,
            resource: checkerboardSampler
         },
         {    // The texture.  Note that the resource is a view of the texture.
            binding: 1,
            resource: checkerboardTexture.createView()
         },
         {    // The resource is the buffer containing the uniform variable.
            binding: 2,
            resource: {buffer: uniformBuffer, offset: 0, size: 4}
         }
      ]
   });
   
   bindGroup = checkerboardBindGroup;  // Initially, the checkerboard texture is used.
}


function draw() {
   let commandEncoder = device.createCommandEncoder();
   let renderPassDescriptor = {
      colorAttachments: [{
          clearValue: { r: 0.85, g: 0.85, b: 0.85, a: 1 }, 
          loadOp: "clear",
          storeOp: "store", 
          view: context.getCurrentTexture().createView() // for drawing to the canvas
      }]
   };
   let passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);
   passEncoder.setPipeline(pipeline);
   passEncoder.setVertexBuffer(0,vertexBuffer);  // (includes vertex coordinates)
   passEncoder.setBindGroup(0,bindGroup);  // (includes texture and sampler)
   passEncoder.draw(4);
   passEncoder.end();
   let commandBuffer = commandEncoder.finish();
   device.queue.submit([commandBuffer]);
}


/**
 *  This function is called if and when the Mona Lisa texture image has been
 *  successfully loaded.  The parameter is the image bitmap, obtained from
 *  the downloaded image.  This function creates the texture, writes the
 *  image data to it, creates an appropriate sampler for the texture,
 *  creates the bind group that contains the sampler and texture, and
 *  enables the third option in the radio group on the web page to allow
 *  the user to select the Mona Lisa texture.
 */
function textureLoaded(imageData) {
    let imageTexture = device.createTexture({
           // Create the texture.  The size comes from the image data.
           // The usage is required in order to use copyExternalImageToTexture
        size: [imageData.width, imageData.height],
        format: 'rgba8unorm',
        usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST |
                    GPUTextureUsage.RENDER_ATTACHMENT
    });
    device.queue.copyExternalImageToTexture(
          // Copy the image bitmap to the GPU
       { source: imageData },
       { texture: imageTexture },
       [imageData.width, imageData.height]
    );
    let imageSampler = device.createSampler({
          // Create a sampler with min and max filters set to "linear".
          // The default address modes, "clamp-to-edge", are OK because
          // this program does not use texcoords outside the range 0 to 1
          // for the Mona Lisa texture; it is just shown once on the square.
       minFilter: "linear",  // Note: default is "nearest".
       magFilter: "linear"
    });
    imageBindGroup = device.createBindGroup({
           // Create the bind group that will be attached to the pipeline
           // for drawing the square with the Mona Lisa texture.
        layout: bindGroupLayout,
        entries: [
           {
              binding: 0,
              resource: imageSampler  // The sampler configured for the Mona Lisa texture.
           },
           {
              binding: 1,
              resource: imageTexture.createView()  // A view of the Mona Lisa texture.
           },
           {
              binding: 2,
              resource: {buffer: uniformBuffer, offset: 0, size: 4}
           }
        ]
     
    });
    document.getElementById("tex3").disabled = false; // enable the 3rd radio button
}


/**
 * Start loading the Mona Lisa image for the third texture choice, using
 * the fecth API.  The image must be at URL "textures/mona-lisa.jpg" relative
 * to this page.  Once the texture image has been successfully loaded,
 * the function textureLoaded() will be called to create the texture.
 * The technique here is typical for loading image files for use as a
 * texture, but see the commented out alternative version below.
 */
function loadImageTexture() {
    fetch("textures/mona-lisa.jpg")
       .then( response => response.blob() )
       .then( blob => createImageBitmap(blob) )
       .then( bitmap => textureLoaded(bitmap) )
       .catch( e => { document.getElementById("message2").innerHTML =
                         "Could not load the Mona Lisa texture image!";
                      console.log("Error loading image: ", e);
                     } )
}
/*
// An alternative version of loadImageTexture(), using an HTMLImageElement.
// Note: Safari might not be able to use createImageBitmap on a blob?
// (But as I write this, Safari doesn't do WebGPU either.)
function loadImageTexture() {
   let img = document.createElement("img");
   img.onload = async () => textureLoaded(await createImageBitmap(img));
   img.onerror = (e) => { document.getElementById("message2").innerHTML =
                             "Could not load the Mona Lisa texture image!";
                          console.log("Error loading image: ", e);
                         };
   img.src = "textures/mona-lisa.jpg";
}
*/


/**
 *  This function is called when the user selects a radio button.  The parameter
 *  is 1, 2, or 3, indicating which texture is to be shown on the square.
 *  The parameter value is written to the uniform buffer, to tell the fragment
 *  shader which texture to use.  The global variable bindGroup is set to the
 *  correct bind group for using the selected texture; it will be attached to
 *  the pipeline when the image is drawn.
 */
function setTexture( n ) {
   device.queue.writeBuffer(uniformBuffer, 0, new Uint32Array([n]));
     // Note: for n = 1, it doesn't matter which bind group is used, since
     // in that case, the fragment shader doesn't use the sampler or texture,
     // and the same uniform buffer is in both bind groups.
   if (n === 2)
      bindGroup = checkerboardBindGroup;
   else if (n === 3)
      bindGroup = imageBindGroup;
   draw(); // Redraw the image to show the change in texture.
}


async function init() {
   try {
      await initWebGPU();
      createPipelineConfig();
   }
   catch (e) {
       document.getElementById("message").innerHTML =
          "<span style='color:#AA0000; font-size:110%'><b>Error: Could not initialize WebGPU: </b>" + 
                    e.message + "</span>";
       return;
   }
   document.getElementById("tex3").disabled = true; // Disable until image has been loaded.
   document.getElementById("tex2").checked = true;  // Default textue selection is 2.
   document.getElementById("tex1").onchange = function() { setTexture(1); };
   document.getElementById("tex2").onchange = function() { setTexture(2); };
   document.getElementById("tex3").onchange = function() { setTexture(3); };
   draw();
   loadImageTexture(); // Start loading the image.
}

window.onload = init;

</script>
</head>

<body>

<h2>WebGPU First Texture Example</h2>

<noscript><h3>Error: This page requires JavaScript and a web browser that supports WebGPU!</h3><hr></noscript>

<p id="message"></p>

<p style="margin-left:30px"><b>Select Texture:</b></p>

<p style="margin-left:70px">
   <label><input type="radio" name="tex" id="tex1">
       Use texture coordinates as red/green color components</label>
   <br><label><input type="radio" name="tex" id="tex2">
       Use a pink/blue/yellow checkerboard pattern defined as data</label>
   <br><label><input type="radio" name="tex" id="tex3">
       Use a Mona Lisa texture defined from an image.</label>
</p>

<p style="color:red"><b id="message2">&nbsp;</b></p>


<div id="canvasholder">
<canvas width=500 height=500 id="webgpuCanvas"></canvas>
</div>

</body>
</html>

