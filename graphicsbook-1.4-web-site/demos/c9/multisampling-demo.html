<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>WebGPU Multisampling Demo</title>
<link rel="stylesheet" href="../demo.css">
<script src="../script/demo-core.js"></script>
<script>
   "use strict";

const shaderSource = `
   
   struct VertexOutput {
       @builtin(position) position : vec4f,
       @location(0) color : vec4f
   }
   @vertex
   fn vertexMain( 
          @location(0) coords : vec2f,
          @location(1) offset : vec2f,
          @location(2) color : vec3f ) -> VertexOutput {
      var output : VertexOutput;
      output.position = vec4f( coords + offset, 0, 1 );
      output.color = vec4f(color,1);
      return output;
   }
   
   @fragment
   fn fragmentMain( @location(0) color : vec4f) -> @location(0) vec4f{
      return color;
   }
`;

const VERTEX_COUNT = 32;
const INSTANCE_COUNT = 50;

let vertexCoords = new Float32Array(2*VERTEX_COUNT);
let instanceOffsets = new Float32Array(2*INSTANCE_COUNT);
let instanceColors = new Float32Array(3*INSTANCE_COUNT);
let velocities = new Float32Array(2*INSTANCE_COUNT);

let context;
let device; 

let shader;
let pipeline;
let multisamplingPipeline;

let vertexBuffer;

let instanceOffsetBuffer;
let instanceColorBuffer;

let textureForMultisampling;    // Used only for multisampling.
let textureViewForMultisampling;


async function initWebGPU() {

   if (!navigator.gpu) {
      throw Error("WebGPU not supported in this browser.");
   }
   let adapter = await navigator.gpu.requestAdapter();
   if (!adapter) {
      throw Error("WebGPU is supported, but couldn't get WebGPU adapter.");
   }

   device = await adapter.requestDevice();
   
   let canvas = document.getElementById("webgpuCanvas");
   context = canvas.getContext("webgpu");
   context.configure({
      device: device,
      format: navigator.gpu.getPreferredCanvasFormat(),
      alphaMode: "premultiplied"
   });

   device.pushErrorScope("validation");
   shader = device.createShaderModule({
      code: shaderSource
   });
   let error = await device.popErrorScope();
   if (error) {
      throw Error("Compilation error in shader; see Console for details.");
   }   
}



function createPipelineConfig() {

   let vertexBufferLayout = [
      { 
         attributes: [ { shaderLocation:0, offset:0, format: "float32x2" } ],
         arrayStride: 8,
         stepMode: "vertex" 
      },
      { 
         attributes: [ { shaderLocation:1, offset:0, format: "float32x2" } ],
         arrayStride: 8,
         stepMode: "instance" 
      },
      {
         attributes: [ { shaderLocation:2, offset:0, format: "float32x3" } ],
         arrayStride: 12,
         stepMode: "instance" 
      }
   ];
      
   let multisamplingPipelineDescriptor = {
       vertex: {
          module: shader,
          entryPoint: "vertexMain",
          buffers: vertexBufferLayout
       },
       fragment: {
          module: shader,
          entryPoint: "fragmentMain",
          targets: [{
            format: navigator.gpu.getPreferredCanvasFormat()
          }]
       },
       primitive: {
          topology: "triangle-strip"
       },
       multisample: {
         count: 4,
       },
       layout: "auto"
   };
    
   multisamplingPipeline = device.createRenderPipeline(multisamplingPipelineDescriptor);  
   
   let pipelineDescriptor = {
       vertex: {
          module: shader,
          entryPoint: "vertexMain",
          buffers: vertexBufferLayout
       },
       fragment: {
          module: shader,
          entryPoint: "fragmentMain",
          targets: [{
            format: navigator.gpu.getPreferredCanvasFormat()
          }]
       },
       primitive: {
          topology: "triangle-strip"
       },
       multisample: {
         count: 1,
       },
       layout: "auto"
   };
    
   pipeline = device.createRenderPipeline(pipelineDescriptor);  
   
   vertexBuffer = device.createBuffer({ 
       size: vertexCoords.byteLength, 
       usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST
   });   
   device.queue.writeBuffer(vertexBuffer, 0, vertexCoords); 
   
   instanceOffsetBuffer =  device.createBuffer({ 
       size: instanceOffsets.byteLength, 
       usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST
   });   
   device.queue.writeBuffer(instanceOffsetBuffer, 0, instanceOffsets); 
   
   instanceColorBuffer =  device.createBuffer({ 
       size: instanceColors.byteLength, 
       usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST
   });   
   device.queue.writeBuffer(instanceColorBuffer, 0, instanceColors);
      
   textureForMultisampling = device.createTexture({ // Used only for multisampling.
      size: [context.canvas.width, context.canvas.height],
      sampleCount: 4,  // (4 is actually the only value.)
      format: navigator.gpu.getPreferredCanvasFormat(),
      usage: GPUTextureUsage.RENDER_ATTACHMENT,
    });
    textureViewForMultisampling = textureForMultisampling.createView();
}


function initializeDataArrays() {

   vertexCoords[0] = 0.1;
   vertexCoords[1] = 0;
   for (let i = 1; i <= VERTEX_COUNT/2 - 1; i++) {
      let angle = 2*Math.PI/VERTEX_COUNT * i
      vertexCoords[4*(i-1)+2] = 0.1 * Math.cos(angle);
      vertexCoords[4*(i-1)+3] = -0.1 * Math.sin(angle);
      vertexCoords[4*(i-1)+4] = 0.1 * Math.cos(angle);
      vertexCoords[4*(i-1)+5] = 0.1 * Math.sin(angle);
   }
   vertexCoords[2*VERTEX_COUNT-2] = -0.1;
   vertexCoords[2*VERTEX_COUNT-1] = 0;
   
   for (let i = 0; i < INSTANCE_COUNT; i++) {
       instanceOffsets[2*i] = 1.8*Math.random() - 0.9;
       instanceOffsets[2*i+1] = 1.8*Math.random() - 0.9;
       let speed = 0.05 + 0.3*Math.random();
       let theta = 2*Math.PI*Math.random();
       velocities[2*i] = speed*Math.cos(theta);
       velocities[2*i+1] = speed*Math.sin(theta);
       instanceColors[3*i] = Math.random();
       instanceColors[3*i+1] = Math.random();
       instanceColors[3*i+2] = Math.random();
   }   
}


function draw() {
   let multisampled = document.getElementById("multisample").checked
   let commandEncoder = device.createCommandEncoder();
   let renderPassDescriptor;
   if (multisampled) { 
      renderPassDescriptor = {
         colorAttachments: [{
             clearValue: {r: 1, g: 1, b:1, a: 1 }, 
             loadOp: "clear", 
             storeOp: "store", 
             view: textureViewForMultisampling, 
             resolveTarget: context.getCurrentTexture().createView()
         }]
      };
   }
   else {
      renderPassDescriptor = {
         colorAttachments: [{
             clearValue: {r: 1, g: 1, b:1, a: 1 }, 
             loadOp: "clear", 
             storeOp: "store", 
             view: context.getCurrentTexture().createView()
         }]
      };
   }
   let passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);
   if (multisampled) {
      passEncoder.setPipeline(multisamplingPipeline);
   }
   else {
      passEncoder.setPipeline(pipeline);
   }
   passEncoder.setVertexBuffer(0,vertexBuffer);
   passEncoder.setVertexBuffer(1,instanceOffsetBuffer);
   passEncoder.setVertexBuffer(2,instanceColorBuffer);
   passEncoder.draw(VERTEX_COUNT,INSTANCE_COUNT);
   passEncoder.end();
   let commandBuffer = commandEncoder.finish();
   device.queue.submit([commandBuffer]);
}


let running = false;
let previousTime;


function doFrame() {
   if (!running)
      return;
   let now = performance.now();
   let dt = (now - previousTime)/1000;
   previousTime = now;
   for (let i = 0; i < INSTANCE_COUNT; i++) {
       let x = 2*i;
       let y = 2*i+1;
       instanceOffsets[x] += velocities[x] * dt;
       instanceOffsets[y] += velocities[y] * dt;
       if (instanceOffsets[x] > 0.9) {
           velocities[x] = -velocities[x];
           instanceOffsets[x] = 1.8 - instanceOffsets[x];
       }
       else if (instanceOffsets[x] < -0.9) {
           velocities[x] = -velocities[x];
           instanceOffsets[x] = -1.8 - instanceOffsets[x];
       }
       if (instanceOffsets[y] > 0.9) {
           velocities[y] = -velocities[y];
           instanceOffsets[y] = 1.8 - instanceOffsets[y];
       }
       else if (instanceOffsets[y] < -0.9) {
           velocities[y] = -velocities[y];
           instanceOffsets[y] = -1.8 - instanceOffsets[y];
       }
   }
   device.queue.writeBuffer(instanceOffsetBuffer,0,instanceOffsets);
   draw();
   requestAnimationFrame(doFrame);
}


function doAnimateCheckbox() {
   let anim = document.getElementById("anim").checked;
   if (anim == running)
      return;
   running = anim;
   if (running) { // Animation is being started.
      previousTime = performance.now();
      requestAnimationFrame(doFrame);
   }
}
   
async function init() {
   try {
      await initWebGPU();
      initializeDataArrays();
      createPipelineConfig();
   }
   catch (e) {
       document.getElementById("canvas-holder").innerHTML =
          "<p style='color:#AA0000; font-size:110%'><b>Error: Could not initialize WebGPU: </b>" + 
                    e.message + "</p>";
       return;
   }
   draw();
   document.getElementById("multisample").checked = true;
   document.getElementById("multisample").onchange = draw;
   document.getElementById("anim").checked = false;
   document.getElementById("anim").onchange = doAnimateCheckbox;
}

</script>
</head>
<body onload="init()">

<div id="content">

<h3 id="headline">WebGPU Multisampling Demo</h3>


<p><label><input type=checkbox id="multisample" checked> <b>Use Multisampling</b></label>
   <label style="margin-left:30px"><input type=checkbox id="anim"> <b>Animate</b></label>
</p>

<div id="canvas-holder">
<canvas id="webgpuCanvas" width="350" height="350"></canvas>
</div>

</div>



<div id="help-content" style="display:none">
<h3>About this demo...</h3>
<p>If you uncheck the "Use Multisampling" checkbox, you will see
that the edges of the disks now have a more jagged appearance.
The effect is subtle.
It will be more obvious if you increase the magnificaion of
the web page.</p>
<p>The effect might be less visible when animation is turned on,
but again, the effect is very clear &mdash; and interesting &mdash; on a highly magnified
web page.</p>
<p>Multisampling is a kind of antialiasing.  Without multisampling,
WebGPU gets a color for a pixel by evaluating the fragment shader
at one point in that pixel.  With multitasking, it evaluates
the fragment shader at several points in the pixel and averages
the results.  This can cut down on "jaggies" and give a smoother
appearance.</p>
</div>


<!-- support for help text -- do not change. -->
<div id="help-icon">
<img src="../image/question32.png" onclick="showDemoHelp()"
    title="Click here for information about this demo." width="32" height="32">
</div>
<div id="hide-help-icon">
<img src="../image/close32.png" onclick="showDemoHelp()"
    title="Click here to return to the demo." width="65" height="32">
</div>
<div id="helpBG" style="display:none"></div>
</body>
</html>
