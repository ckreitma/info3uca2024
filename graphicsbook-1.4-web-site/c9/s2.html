<!DOCTYPE html>
<html>
<head>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Introduction to Computer Graphics, Section 9.2 -- Instances and Indices</title>
<link type="text/css" rel="stylesheet" href="../resource/graphicstext.css">
</head>
<body>
<div class="page">
<div align="right">
<small>
        [  <a href="s1.html">Previous Section</a> |
           <a href="s3.html">Next Section</a> |
           <a href="index.html">Chapter Index</a> | 
	    <a href="../index.html">Main Index</a> ]
    </small>
</div>
<hr>
<table class="subsections" cellpadding="5" border="2">
<tr>
<td>
<div align="center">
<b>Subsections</b>
<hr>
<small><a href="#webgpu.2.1">Instanced Drawing</a>
<br>
<a href="#webgpu.2.2">Indexed Drawing</a>
<br>
<a href="#webgpu.2.3">Drawing Multiple Primitives</a>
<br>
<a href="#webgpu.2.4">Using Indices in Shaders</a>
<br>
<a href="#webgpu.2.5">Multisampling</a>
<br>
</small>
</div>
</td>
</tr>
</table>
<div class="content section">
<h3 class="section_title">Section 9.2</h3>
<h2 class="section_title">Instances and Indices</h2>
<hr class="break">


<p class="firstpar">The previous section showed how to draw one primitive in WebGPU.  In this section
we will see how to draw more than one primitive in the same image, and we will cover
some new options for drawing them: <span class="word" data-term="instanced drawing" data-definition="The ability to render multiple versions of a primitive
with a single function call.  Each copy can have its own values for certain attributes, such as
color or transformation." title="Click for a definition of instanced drawing.">instanced drawing</span>
and <span class="word" data-term="indexed drawing" data-definition="In WebGPU, drawing a primitive using the
drawIndexed() function.  With that function, vertices are not generated
in the order in which they are listed.  Instead, a list of vertex indices
in an index buffer determines the order of the vertices.  Indexed drawing
is used to render indexed face sets." title="Click for a definition of indexed drawing.">indexed drawing</span>.</p>


<p>For most of
this section, we will be looking at variations on one example: an app
that shows randomly colored disks moving around in a canvas.  The last 
variation will add antialiasing to the example using a technique called
multisampling.  Here is a demo that lets you switch between the
basic version and the multisampling version.  The edges of the disks
in the basic version are more jagged.  The effect will be easier to see if
you magnify the web page.</p>

<div class="demo">
<noscript>
<h4 style="color:red; text-align:center">Demos require JavaScript.<br>Since JavaScript is not available,<br>the demo is not functional.</h4>
</noscript>
<p align="center">
<iframe src="../demos/c9/multisampling-demo.html" width="390" height="450"></iframe>
</p>
</div>



<div class="subsection">
<hr class="break">
<h3 class="subsection_title" id="webgpu.2.1">9.2.1&nbsp;&nbsp;Instanced Drawing</h3>


<p>Instanced drawing makes it possible to draw multiple copies, or "instances," of the
same primitive with a single function call.  Instanced drawing
in <span class="word" data-term="WebGL" data-definition="A 3D graphics API for use on web pages.  WebGL programs are written
in the JavaScript programming language and display their images in HTML canvas
elements.  WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with
a few changes to adapt it to the JavaScript language and the Web environment." title="Click for a definition of WebGL.">WebGL</span> 2.0 was covered in <a href="../c6/s1.html#webgl.1.8">Subsection&nbsp;6.1.8</a>.
The sample program <span class="sourceref"><a href="../source/webgpu/instanced_draw.html">webgpu/instanced_draw.html</a></span>
shows how to do it in WebGPU.  (Again, I urge you to read the
comments in the source code for all sample programs!)</p>


<p>The various instances of the primitive can look different in the
rendered image, provided that they have different values for some
attributes.  For example, the instances can have different colors.  
The color would be an "instance attribute."</p>


<p>We have used the render pass encoder method <span class="code">draw(N)</span> to draw
a primitive that has N vertices.  For each vertex, the system will
pull attribute values from vertex buffers for that vertex and will
pass them as parameters to the vertex shader entry point.  Instance
properties work the same way, except that the value for an
instance attribute is the same for every vertex in a given instance.</p>


<p>Instanced drawing uses the same <span class="code">draw()</span> method as
regular drawing, but with a second parameter.  A call to <span class="code">draw(N,M)</span>
will draw M instances of a primitive that has N vertices.  The effect is
similar to the following pseudocode:</p>


<pre>for (i = 0; i &lt; M; i++)
    get instance attribute values for instance i
    for (v = 0; v &lt; N; v++)
       get vertex attribute values for vertex v
       call vertex shader function, passing in all attribute values</pre>


<p class="noindent">(The <span class="code">draw()</span> method can also take two more optional parameters specifying
the start index for the vertices and the start index for the instances.)</p>


<p>Vertex attribute values come from vertex buffers.  So do instance attribute values.
The only difference is a small change in the vertex buffer layout specification.
It's time to look at an example.  The sample program draws fifty colored disks
which a single call to <span class="code">draw()</span>.  The basic primitive is a disk
centered at (0,0).  The coordinates for the vertices of the disk are given as
a vertex attribute.  Each colored disk is an instance. The color of the disk
is an instance attribute.  Another instance attribute, <span class="code">offset</span>,
specifies a <span class="word" data-term="translation" data-definition="A geometric transform that adds a given translation amount to
each coordinate of a point.  Translation is used to move objects without changing their
size or orientation." title="Click for a definition of translation.">translation</span> transformation that is applied to the
primitive.  In the shader source code, the vertex coordinates, color, and
offset are parameters to the vertex shader function:</p>


<pre>@vertex
fn vertexMain( 
          @location(0) coords : vec2f,
          @location(1) offset : vec2f,
          @location(2) color : vec3f
       ) -&gt; VertexOutput {
   var output : VertexOutput; // (A struct with position and color fields.)
   output.position = vec4f( coords + offset, 0, 1 );
   output.color = vec4f(color,1);
   return output;
}</pre>
 

<p class="noindent">Recall that the <span class="code">@location</span> attributes in the parameter list
are used to associate the parameters with values coming from the JavaScript
side of the program.  The association is made by the <span class="code">shaderLocation</span>
properties in the vertex buffer layout on the JavaScript side.
Here is the layout from the sample program, which specifies the
source for each parameter:</p>
 

<pre>let vertexBufferLayout = [
   { // First vertex buffer, for vertex coord.
      attributes: [ 
        { shaderLocation:0, offset:0, format: "float32x2" }
      ],
      arrayStride: 8,
      stepMode: "vertex"   // This is a vertex attribute.
   },
   { // Second vertex buffer, for instance offsets.
      attributes: [ 
         { shaderLocation:1, offset:0, format: "float32x2" }
      ],
      arrayStride: 8,
      stepMode: "instance"  // This is an instance attribute.
   },
   { // Third vertex buffer, for instance colors.
      attributes: [ 
         { shaderLocation:2, offset:0, format: "float32x3" }
      ],
      arrayStride: 12,
      stepMode: "instance"  // This is an instance attribute.
   }
];</pre>


<p class="noindent">As you can see, the only difference between vertex and instance attributes is
the value of the <span class="code">stepMode</span> property.  Step mode "vertex" tells the
system to pull a value from the vertex buffer for each vertex in the primitive.
Step mode "instance" means to pull out a value for each instance.</p>


<p>The disks in the sample program can be animated.  To draw the next frame
in the animation, the program simply computes a new value for the
offset attribute of each disk, writes the new values to the vertex buffer
that holds the offsets on the GPU side, and then re-renders the image.
One technical point about animation might be bothering you: The JavaScript side of the
program simply enqueues commands that will be executed later on the
GPU side.  Somehow, the two sides have to be synchronized, 
to make sure that we don't start drawing a new image until the old 
image has been computed and displayed on the web page.  That synchronization is taken care
of by the <span class="code">requestAnimationFrame()</span> method that is used to
implement the animation.  That method will not start a new frame until
the previous frame is complete.</p>


<hr class="break">


<p>Although it is not related to instanced drawing, another interesting point
from the sample program is how it draws a disk.  The disk is approximated as
a polygon.  In WebGL, I would draw the disk as a TRIANGLE_FAN, but WebGPU
lacks that primitive type.  Here, the disk is drawn using a triangle-strip
primitive, which requires a careful ordering of the vertices:</p>


<p align="center">
<img src="triangle-strip-disk.png" width="564" height="194" alt="How to draw a disk as a triangle strip"></p>


</div>



<div class="subsection">
<hr class="break">
<h3 class="subsection_title" id="webgpu.2.2">9.2.2&nbsp;&nbsp;Indexed Drawing</h3>


<p>Another way to draw a disk is as a triangle-list primitive, with the disk divided up
like the slices of a pie.  The vertices for one of the triangles would be the center of the
disk plus two consecutive vertices on the circumference. Note that a given vertex can
be used in several different triangles.  This means that the disk can be implemented most efficiently
as an <span class="word" data-term="indexed face set" data-definition=" (IFS). A data structure that represents a polyhedron or polygonal
mesh.  The data structure includes a numbered list of vertices and a list of faces.  A face
is specified by listing the indices of the vertices of the face; that is, a face is given as 
a list of numbers where each number is an index into the list of vertices." title="Click for a definition of indexed face set.">indexed face set</span>.  The
data for an indexed face set consists of a list of vertex coordinates (plus corresponding
lists of values for other vertex attributes if needed) and a list of vertex indices.
(See <a href="../c3/s4.html#gl1geom.4.1">Subsection&nbsp;3.4.1</a> for the more details.)</p>


<p>A WebGPU render pass encoder has a <span class="code">drawIndexed(N)</span> method that implements
this type of drawing.  In addition to vertex buffers, this method requires an
<span class="newword" data-term="index buffer" data-definition="In WebGPU, an index buffer is a GPU buffer that holds
vertex indices for use with the drawIndexed().  A vertex index gives the position
of a vertex in the list of vertices of a primitive." title="Click for a definition of index buffer.">index buffer</span> to hold the vertex indices.  The values in the
index buffer must be either 16-bit unsigned integers or 32-bit unsigned integers.
The effect of <span class="code">drawIndexed(N)</span> is</p>


<pre>for (i = 0; i &lt; N; i++)
    Let v be index number i from the index buffer
    get attribute values for vertex v from the vertex buffers
    call the vertex shader function, passing in the attribute values</pre>


<p>The sample program <span class="sourceref"><a href="../source/webgpu/indexed_draw.html">webgpu/indexed_draw.html</a></span> draws a single
disk as a triangle-list primitive using <span class="code">drawIndexed()</span>.  To add a little
interest, it also draws the circumference of the disk as a line-strip primitive,
using the basic <span class="code">draw()</span> method.  So the same program also shows
how to render two primitives in the same render pass.</p>


<p>In the program, <span class="code">VERTEX_COUNT</span> is the number of vertices of the
polygon that is used to approximate the disk.  The vertices are numbered in
counterclockwise order around the disk, with vertex number&nbsp;0 repeated at
the end.  The <span class="code">VERTEX_COUNT+1</span> vertices can then be used in 
order to draw the outline of the disk as a line-strip.  For drawing the
interior of disk, we will also need to have the center of the disk, (0,0),
in the list.  The center is added as vertex number <span class="code">VERTEX_COUNT+1</span>.
To render the interior, we need to draw <span class="code">3*VERTEX_COUNT</span>
vertices&mdash;three vertices for each triangle. The data for the index
buffer is loaded into a JavaScript <span class="classname">Uint16Array</span> of
length <span class="code">3*VERTEX_COUNT</span>:</p>


<pre>/* Fill diskIndices with the vertex indices for the VERTEX_COUNT
 * triangles that make up the disk.  Each triangle uses the center
 * of the disk and two consecutive vertices on the outline. */

for (let i = 0; i &lt; VERTEX_COUNT; i++) {
    diskIndices[3*i] = VERTEX_COUNT+1;  // center of disk
    diskIndices[3*i+1] = i;             // vertex number i
    diskIndices[3*i+2] = i+1;           // vertex number i+1
}</pre>


<p class="noindent">A buffer is created to hold the indices on the GPU side, and the
values in <span class="code">diskIndices</span> are written to that buffer:</p>


<pre>indexBuffer = device.createBuffer({ 
     size: diskIndices.byteLength, 
     usage: GPUBufferUsage.INDEX | GPUBufferUsage.COPY_DST
  });
device.queue.writeBuffer(indexBuffer, 0, diskIndices);</pre>


<p class="noindent">The <span class="code">GPUBufferUsage.INDEX</span> indicates that the buffer
will be used as an index buffer.  Otherwise, this is the same
as creating a vertex buffer.  But unlike vertex buffers, an index buffer is not
attached to a pipeline.  Instead, it is specified when creating the
render pass:</p>


<pre>passEncoder.setIndexBuffer(indexBuffer, "uint16");</pre>


<p class="noindent">The second parameter says that the indices are 16-bit unsigned integers;
the alternative is "uint32" for 32-bit integers.</p>


<p>It will be worthwhile to look at the full code for rendering the
disk interior and outline.  The interior and the outline use different
primitive topologies.  Since the primitive topology is a property
of the render pipeline, we need to use separate pipelines for the
interior and for the outline.  Since the pipeline is an aspect of
a rendering pass, we need to encode two render passes:</p>


<pre>function draw() {
   let commandEncoder = device.createCommandEncoder();
   let renderPassDescriptor = {
      colorAttachments: [{
          clearValue: { r: 1, g: 1, b: 1, a: 1 }, // White background.
          loadOp: "", // To be assigned later!
          storeOp: "store",
          view: context.getCurrentTexture().createView()
      }]
   };
   
   /* First render pass draws the disk, using a "triangle-list" topology. */
   
   renderPassDescriptor.colorAttachments[0].loadOp = "clear";
   let passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);
   passEncoder.setPipeline(pipelineForDisk); // uses "triangle-list"
   passEncoder.setVertexBuffer(0,vertexBuffer);
   passEncoder.setIndexBuffer(indexBuffer, "uint16"); 
   passEncoder.drawIndexed( 3*VERTEX_COUNT ); // 3 vertices per triangle.
   passEncoder.end();
   
   /* Second render pass draws the outline, using a "line-strip" topology. */
   
   renderPassDescriptor.colorAttachments[0].loadOp = "load"; // DON'T clear!
   passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);
   passEncoder.setPipeline(pipelineForOutline); // uses "line-strip"
   passEncoder.setVertexBuffer(0,vertexBuffer);
   passEncoder.draw(VERTEX_COUNT+1);
   passEncoder.end();
   
   let commandBuffer = commandEncoder.finish(); 
   device.queue.submit([commandBuffer]);
}</pre>


<p class="noindent">Note that for the first render pass, the <span class="code">loadOp</span> is "clear",
since we want to fill the image with the background color before rendering
the disk.  For the second render pass, we want to draw the outline on
top of the existing image, so the <span class="code">loadOp</span> must be "load".  The same
<span class="code">renderPassDescriptor</span> can be used for both passes, with just the
<span class="code">loadOp</span> property changed.</p>


</div>



<div class="subsection">
<hr class="break">
<h3 class="subsection_title" id="webgpu.2.3">9.2.3&nbsp;&nbsp;Drawing Multiple Primitives</h3>


<p>I would like to draw the outlines of the colored disks in my moving disk example.  However
I can't simply use instanced drawing to draw all the disks, then use it again to draw the outlines,
since that would show the complete outline of every disk, even parts of the outline that
should be hidden by other disks.  (Actually, I can do that if I add a <span class="word" data-term="depth test" data-definition="A solution to the hidden surface problem that involves keeping
track of the depth, or distance from the viewer, of the object currently visible at each
pixel in the image.  When a new object is drawn at a pixel, the depth of the new object
is compared to the depth of the current object to decide which one is closer to the viewer.
The advantage of the depth test is that objects can be rendered in any order.  A disadvantage
is that only a limited range of depths can be represented in the image." title="Click for a definition of depth test.">depth test</span>
to the program (see <a href="../c9/s4.html#webgpu.4.1">Subsection&nbsp;9.4.1</a>).)  A&nbsp;solution is to abandon
instanced drawing and draw each disk separately.  That's what I do in the sample program
<span class="sourceref"><a href="../source/webgpu/draw_multiple.html">webgpu/draw_multiple.html</a></span>.  That program also introduces a few new
WebGPU features.</p>


<p>Each disk in the new program is drawn in the same
way as the single disk in <span class="sourceref"><a href="../source/webgpu/indexed_draw.html">webgpu/indexed_draw.html</a></span>.  The problem is that the
disks have different colors and offsets.  In <span class="sourceref"><a href="../source/webgpu/instanced_draw.html">webgpu/instanced_draw.html</a></span>,
the color and offset were instance properties that came from vertex buffers, and their 
values were passed as parameters into the vertex shader function.  In the new program, they
are moved into a uniform variable in the shader program:</p>


<pre>struct DiskInfo {
    color : vec3f,  // interior color for the disk
    offset : vec2f  // translation applied to the disk
}

@group(0) @binding(0) var&lt;uniform&gt; diskInfo : DiskInfo;</pre>


<p class="noindent">The values for the uniform variable are stored in a uniform buffer.
Before drawing each disk, the color and offset for that disk must be
copied into the uniform buffer.  The basic idea is simple:</p>


<pre>for each disk:
    copy offset and color for that disk to the uniform buffer
    do a render pass to draw the disk interior
    do a render pass to draw the disk outline</pre>


<p class="noindent">Previously, we have used <span class="code">device.queue.writeBuffer()</span> to copy
data from the JavaScript side into a buffer on the GPU.  That would work,
provided that we use a new command encoder for each iteration of the loop.
(In fact, that's what I do in an alternative version of the program,
<span class="sourceref"><a href="../source/webgpu/draw_multiple_2.html">webgpu/draw_multiple_2.html</a></span>.  See the comments in that
program for more information.)</p>



<p>However, I decided to complicate
things&mdash;and hopefully make the program a little more efficient&mdash;by
using a single command encoder to do all the drawing.  But that
makes it impossible to use <span class="code">writeBuffer()</span>.  Let's see why.
A command encoder doesn't execute commands, it just makes a list of
commands that will be submitted to the device queue in a batch
after the list is complete.  Similarly, when <span class="code">writeBuffer()</span>
is called, it doesn't immediately write to the buffer.  But it does
immediately add a command to the device queue to do the writing.
If we do the calls to <span class="code">writeBuffer()</span> in the middle of
collecting the draw commands in a command encoder, then when we
submit the draw commands in a batch at the end, all the write
commands will already be in the queue.  So, <b>all</b> of the write
commands will actually be executed before <b>any</b> the draw commands.
Only the final write will have any effect on the drawing!</p>


<p>The solution is to replace <span class="code">writeBuffer()</span> with a copy command
that can be encoded and added to the list of commands produced by
a command encoder.  Then, when the list of commands is executed on
the GPU, each copy will be done just before the draw command that uses it.
But since the copying will be done on the GPU, the data that is being copied
must already be in a GPU buffer.  The command that we want is</p>


<pre>commandEncoder.copyBufferToBuffer( <span class="bnf">destinationBuffer</span>, <span class="bnf">destinationStartByte</span>,
        <span class="bnf">sourceBuffer</span>, <span class="bnf">sourceStartByte</span>, <span class="bnf">byteCount</span> );</pre>


<p class="noindent">To implement this, the program copies the color values for all the disks into a
GPU buffer, and copies the offset values into another GPU buffer.  Using buffers for these values is similar
to what we did for instanced drawing, but the buffers in this case are not vertex buffers.
Instead, they are <span class="newword" data-term="storage buffer" data-definition="In WebGPU, a general purpose buffer on the GPU,
which can be used in compute shaders as well as in vertex and fragment shaders." title="Click for a definition of storage buffer.">storage buffers</span>, a kind of general purpose
GPU buffer.  They can be used much like uniform buffers but have fewer restrictions
and might be a little less efficient.  Here is how the storage buffer for the
disk colors is created and filled with data as part of program initialization:</p>


<pre>diskColorBuffer =  device.createBuffer({
    size: diskColors.byteLength, 
    usage: GPUBufferUsage.STORAGE | 
                  GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST
});   
device.queue.writeBuffer(diskColorBuffer, 0, diskColors);</pre>


<p class="noindent">The <span class="code">usage</span> property includes <span class="code">STORAGE</span> because
the buffer is a storage buffer; it includes <span class="code">COPY_SRC</span> so that the buffer
can be used as the source buffer in <span class="code">copyBufferToBuffer()</span>; and
it includes <span class="code">COPY_DST</span> so that the buffer can be used as the
destination buffer in <span class="code">writeBuffer()</span>.</p>


<p>When a storage buffer is used in a shader program, it must be part of
a bind group.  In this program, however, the storage buffers are not used
in the shaders, and the only thing in the bind group is the small uniform
buffer that holds the color and offset for one disk at a time.</p>


<p>The command for copying the color for disk number i from the storage
buffer to the uniform buffer then becomes</p>


<pre>commandEncoder.copyBufferToBuffer( diskColorBuffer, 12*i,
                                             uniformBuffer, 0, 12 );</pre>


<p class="noindent">The color data in <span class="code">diskColorBuffer</span> for each disk takes up 
12 bytes (three 32-bit floats), so the starting byte for the color for 
disk number <span class="code">i</span> is <span class="code">12*i</span>.  In <span class="code">uniformBuffer</span>,
the color starts at byte number&nbsp;0.  And the byte count, 12,
is the number of bytes to be copied.</p>


<p>The disk offset is handled in a similar way, but there is one
more issue to deal with: <span class="newword" data-term="alignment (in WGSL)" data-definition="Restrictions on the legal location of
a value in memory, depending on the data type.  For example, the address
of a vec3f variable in WGSL must be a multiple of 16." title="Click for a definition of alignment (in WGSL).">alignment</span>
rules in <span class="word" data-term="WGSL" data-definition="The WebGPU Shader Language, the programming language in which 
shaders for use in WebGPU are written." title="Click for a definition of WGSL.">WGSL</span>.  Alignment refers to restrictions on where
a value can be located in memory.  The restrictions can make memory access more efficient.
For example, the alignment rule for a <span class="code">vec2f</span> says that its
address in memory must be multiple of&nbsp;8 bytes.  The uniform variable,
<span class="code">diskInfo</span>, is a struct that contains a <span class="code">vec3f</span> for the color
followed by a <span class="code">vec2f</span> for the offset.  The <span class="code">vec3f</span>
takes up 12 bytes in memory.  But the alignment rule for the <span class="code">vec2f</span>
says that it must start at a multiple of 8 bytes.  So, an extra byte
of padding is added after the <span class="code">color</span>, moving the starting
byte number for the <span class="code">offset</span> to 16.  When the offset is copied
from the storage buffer to the uniform buffer, the starting byte is 16,
rather than the 12 that you might have expected:</p>


<pre>commandEncoder.copyBufferToBuffer( diskOffsetBuffer, 8*i,
                                             uniformBuffer, <b>16</b>, 8 );</pre>
 

<p>I will have more to say about alignment in <a href="../c9/s3.html#webgpu.3.1">Subsection&nbsp;9.3.1</a>.
You should be able to understand the rest of the <span class="sourceref"><a href="../source/webgpu/draw_multiple.html">program source</a></span>.
As always, read the comments.</p>


</div>



<div class="subsection">
<hr class="break">
<h3 class="subsection_title" id="webgpu.2.4">9.2.4&nbsp;&nbsp;Using Indices in Shaders</h3>


<p>In WebGL, each point in a primitive of type POINTS can have a size.  The point
is rendered as a square with the given size, and the square comes with <span class="word" data-term="texture coordinates" data-definition="Refers to the 2D coordinate system on a texture image, or to
similar coordinate systems for 1D and 3D textures.  Texture coordinates typically range from 0 to 1
both vertically and horizontally, with (0,0) at the lower left corner of the image.  The
term also refers to coordinates that are given for a surface and that are used to specify
how a texture image should be mapped to the surface." title="Click for a definition of texture coordinates.">texture coordinates</span>.
(See <a href="../c6/s2.html#webgl.2.5">Subsection&nbsp;6.2.5</a>.)  In WebGPU, there is no similar idea of point size for
primitives with the point-list topology; the points are just individual pixels, which limits
their usefulness.</p>


<p>Now, in WebGPU, we could easily use instanced drawing to render multiple copies of
a square and do something very similar to the WebGL POINTS primitive.  However, I would
like to use a different approach, to illustrate a new WebGPU feature: using vertex and
instance indices in shaders.  I do that in the sample program
<span class="sourceref"><a href="../source/webgpu/indices_in_shader.html">webgpu/indices_in_shader.html</a></span>, which shows the same moving disks
as the first example in this section but does so in a very different way.</p>


<p>We have seen how parameter values for a vertex shader function can come from
vertex buffers.  But there are also certain "builtin" values that can be used as
parameters.  This includes the vertex index and the instance index of the
vertex that is being processed.  For example, the definition of the vertex
shader function in the sample program is</p>


<pre>@vertex
fn vertMain(
    @builtin(vertex_index) vertexNumInPoint: u32,
    @builtin(instance_index) pointNum: u32
) -&gt; VertexOutput { . . .</pre>


<p class="noindent">If this function is invoked by a call to <span class="code">draw(vertexCt,instanceCt)</span> in
a render pass encoder, the effect is similar to this pseudocode:</p>


<pre>for (instance_index = 0; instance_index &lt; instanceCt; instance_index++)
    for (vertex_index = 0; vertex_index &lt; vertexCt; vertex_index++)
        vertMain( instance_index, vertex_index )</pre>


<p class="noindent">Note that in this example there are no parameter inputs from vertex buffers.
But the job of the function is still to output coordinates and possibly other
data for vertex number <span class="code">vertex_index</span> in instance number
<span class="code">instance_index</span>.  It needs to create that output somehow!</p>


<p>The shader still has access to data from other sources, such as buffers
that are part of bind groups.  In this example, I provide the necessary data in two
storage buffers.  One storage buffer contains a color for each square,
and one contains the coordinates of the center point for each square.
The size of the square is a constant in the shader program.
The output for a vertex consists of coordinates, texture coordinates, and
color for that vertex. Each instance is a square, generated as a triangle-list
primitive with two triangles, so that the number of vertices in an
instance is six.  The coordinates and texture coordinates for
each vertex can be computed from the center point and the size of the
square:</p>


<p align="center">
<img src="square-as-triangle-list.png" width="454" height="106" alt="The coords and texture coords of vertices of a square computed from center point and size"></p>
     

<p class="noindent">For each instance, the vertex shader function is invoked six times, with a vertex
index ranging from 0 to&nbsp;5.  In each invocation, the shader function computes and outputs the
appropriate values for just one vertex.  I won't go into the coding details
here; you can read them in the <span class="sourceref"><a href="../source/webgpu/indices_in_shader.html">sample&nbsp;program</a></span>
source code.</p>


<p>There is one more point of interest in the program:  I really wanted to draw disks, not
squares, and I wanted to have some use for the texture coordinates on the square.
So the fragment shader function uses the texture coordinates for a pixel to
discard that pixel if it lies outside the disk.  (This is similar to what was done in 
WebGL for the <span class="sourceref"><a href="../demos/c6/textured-points.html">demo</a></span> in <a href="../c6/s4.html#webgl.4.2">Subsection&nbsp;6.4.2</a>.)
</p>


</div>



<div class="subsection">
<hr class="break">
<h3 class="subsection_title" id="webgpu.2.5">9.2.5&nbsp;&nbsp;Multisampling</h3>


<p>The final example for this section is <span class="sourceref"><a href="../source/webgpu/multisampling.html">webgpu/multisampling.html</a></span>,
which adds multisampling to the basic moving disks example.  Ordinarily, the
fragment shader entry point function is evaluated once per pixel, at the center point of the pixel.
With multisampling, it is evaluated at several points within each pixel, and the
color for that pixel is obtained by averaging the colors from each of those samples.
This is a kind of antialiasing. For example, when the geometric edge of a primitive 
cuts through a pixel, some sampled points might lie inside the primitive and some
outside.  The color of the pixel will then be a blend of the primitive color and
the background color.  Or, when a texture is applied, the texture color for the
pixel will be a blend of the texture colors at the sampled points.</p>


<p>WebGL will do antialiasing automatically, but in WebGPU, you have to do some
work.  Fortunately, it's not very hard.  There are just a few changes from a
non-multisampled program.  First, you need a texture for multisampling,
and a view of that texture.  (I will admit that I don't understand why this is
needed.) The code for that is a preview of creating textures and texture views:</p>


<pre>textureForMultisampling = device.createTexture({
    size: [context.canvas.width, context.canvas.height],
    sampleCount: 4,  // (1 and 4 are currently the only possible values.)
    format: navigator.gpu.getPreferredCanvasFormat(),
    usage: GPUTextureUsage.RENDER_ATTACHMENT,
});
textureViewForMultisampling = textureForMultisampling.createView();</pre>


<p class="noindent">When drawing the image, the multisampling texture view is used as the <span class="code">view</span>
property in the color attachment of the render pass descriptor.  And the usual
value of that <span class="code">view</span> property, which represents the final image, is moved
to a new <span class="code">resolveTarget</span> property:</p>


<pre>renderPassDescriptor = {
   colorAttachments: [{
      clearValue: { r: 0.9, g: 0.9, b: 0.9, a: 1 }, 
      loadOp: "clear", 
      storeOp: "store", 
      <span class="newcode">view: textureViewForMultisampling, // Render to multisampling texture.
      resolveTarget: context.getCurrentTexture().createView() // Final image.</span>
   }]
};</pre>


<p class="noindent">And finally, a new <span class="code">multisample</span> property must be added to
the render pipeline descriptor, to specify that the pipeline does
multisampled rendering:</p>


<pre>pipelineDescriptor = {
         . . .
    <span class="newcode">multisample: {  // Sets number of samples for multisampling.
       count: 4,     //  (1 and 4 are currently the only possible values).
    },</span>
       . . .</pre>


<p>And that's it!  (Later, we'll see that when multisampling is applied
to a program that uses the depth test, one more small change in necessary,
in the depth buffer configuration.)</p>


</div>



</div>
<hr>
<div align="right">
<small>
        [  <a href="s1.html">Previous Section</a> |
           <a href="s3.html">Next Section</a> |
           <a href="index.html">Chapter Index</a> | 
	    <a href="../index.html">Main Index</a> ]
    </small>
</div>
</div>
</body>
<script src="../resource/glossary.js"></script>
</html>
